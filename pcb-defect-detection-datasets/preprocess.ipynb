{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2680e168",
   "metadata": {},
   "source": [
    "# AI-Driven Optical PCB Inspection for Smartphone Assembly\n",
    "\n",
    "Category: General problem\n",
    "\n",
    "Description: Manual PCB inspections are time-consuming and error-prone. Students can develop a computer vision-based inspection tool to reduce inspection time and avoid costly field returnsâ€”especially critical in high-volume EMS environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e376eb",
   "metadata": {},
   "source": [
    "# AI Project Lifecycle\n",
    "\n",
    "![AI Lifecycle](./assets/lifecycle.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e590abb",
   "metadata": {},
   "source": [
    "## Step 1: Problem Scoping\n",
    "\n",
    "---------------------------\n",
    "\n",
    "FILL ME\n",
    "\n",
    "---------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea4b9b",
   "metadata": {},
   "source": [
    "## Step 2: Data Acquisiton\n",
    "\n",
    "Here, we have gathered data from the following sources, with different types of data:\n",
    "\n",
    "These data sources detail defects on the copper tracks: Used to train Model CopperTrack\n",
    "- DSPCBSD-.v1i.yolov11: https://universe.roboflow.com/pcb-egrla/dspcbsd/dataset/1\n",
    "- PCB_DATASET: https://www.kaggle.com/datasets/akhatova/pcb-defects\n",
    "- DeepPCB-master: https://github.com/tangsanli5201/DeepPCB\n",
    "- MIXED PCB DEFECT DETECTION: https://data.mendeley.com/datasets/fj4krvmrr5/1\n",
    "\n",
    "This dataset contains annotated images of PCBs with some missing soldered components:  It is not used as of now.\n",
    "- PCB defects.v2i.yolov11: https://universe.roboflow.com/uni-4sdfm/pcb-defects/dataset/2\n",
    "\n",
    "These datasets have annotated images of PCBs highlighting actual components, this can be used to identify missing components by comparing it with a known good PCB's output. This is also not used as of now.\n",
    "- pcb-electronic-components-dataset: https://www.kaggle.com/datasets/rahul14112003/pcb-electronic-components-dataset\n",
    "- pcb-oriented-detection: https://www.kaggle.com/datasets/yuyi1005/pcb-oriented-detection\n",
    "- pcb-fault-detection: (Very Poor Quality) https://www.kaggle.com/datasets/animeshkumarnayak/pcb-fault-detection\n",
    "- pcb-component-detection: https://sites.google.com/view/chiawen-kuo/home/pcb-component-detection\n",
    "\n",
    "The nvidia folder has a pre-trained model from https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/pcb_classification, as they do not provide the dataset they used for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1d36924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "from shutil import copyfile\n",
    "import os\n",
    "import os.path as path\n",
    "import shutil\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from tqdm.std import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b979508",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DATA_DIR = Path(\"./final_track_data\")\n",
    "clear_old_data = False\n",
    "if clear_old_data and path.exists(FINAL_DATA_DIR):\n",
    "    shutil.rmtree(FINAL_DATA_DIR)\n",
    "os.mkdir(FINAL_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f53fd1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "    \"Short\",\n",
    "    \"Spur\",\n",
    "    \"Spurious copper\",\n",
    "    \"Open\",\n",
    "    \"Mouse bite\",\n",
    "    \"Hole breakout\",\n",
    "    \"Conductor scratch\",\n",
    "    \"Conductor foreign object\",\n",
    "    \"Base material foreign object\",\n",
    "    \"Missing hole\",\n",
    "]\n",
    "\n",
    "SHORT = 0\n",
    "SPUR = 1  # Extra copper protruding out of the copper track\n",
    "SPURIOUS_COPPER = 2  # Extra copper outside of a track\n",
    "OPEN = 3\n",
    "MOUSE_BITE = 4  # Copper removed from the track\n",
    "HOLE_BREAKOUT = 5  # Hole misaligned\n",
    "SCRATCH = 6\n",
    "CONDUCTOR_FOREIGN_OBJECT = 7\n",
    "BASE_MATERIAL_FOREIGN_OBJECT = 8\n",
    "MISSING_HOLE = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5fad480",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_GROUPS = [\"train\", \"test\", \"valid\"]\n",
    "for g in DATASET_GROUPS:\n",
    "    os.mkdir(FINAL_DATA_DIR / g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "484e83b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metadata for dataset\n",
    "with open(FINAL_DATA_DIR / \"data.yaml\", \"w\") as f:\n",
    "    f.write(\n",
    "        f\"\"\"train: ../train/images\n",
    "val: ../valid/images\n",
    "test: ../test/images\n",
    "\n",
    "nc: {len(CLASSES)}\n",
    "names: [{\",\".join(f\"'{s}'\" for s in CLASSES)}]\n",
    "\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bd9b16",
   "metadata": {},
   "source": [
    "#### Transfer files from one YOLO dataset to another, while mapping class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40d57d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_one_dataset_group(\n",
    "    from_path_top: Path, to_path_top: Path, dataset_group: str, mapping: dict[int, int]\n",
    "):\n",
    "    from_path = from_path_top / dataset_group\n",
    "    to_path = to_path_top / dataset_group\n",
    "    shutil.copytree(from_path / \"images\", to_path / \"images\", dirs_exist_ok=True)\n",
    "    to_labels_path = to_path / \"labels\"\n",
    "    to_labels_path.mkdir(parents=True, exist_ok=True)\n",
    "    for from_child_path in tqdm((from_path / \"labels\").iterdir()):\n",
    "        to_child_path = to_labels_path / from_child_path.name\n",
    "        with open(from_child_path, \"r\") as f:\n",
    "            with open(to_child_path, \"w\") as t:\n",
    "                for line in f:\n",
    "                    class_id, x, y, w, h = line.strip().split()\n",
    "                    new_class_id = str(mapping[int(class_id)])\n",
    "                    t.write(f\"{new_class_id} {x} {y} {w} {h}\\n\")\n",
    "\n",
    "\n",
    "def map_dataset(from_path_top: Path, to_path_top: Path, mapping: dict[int, int]):\n",
    "    for g in tqdm(DATASET_GROUPS):\n",
    "        map_one_dataset_group(from_path_top, to_path_top, g, mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de3f24f",
   "metadata": {},
   "source": [
    "#### Converting Pascal VOC Format of Dataset to YOLO Format\n",
    "\n",
    "**Pascal VOC** : $(x_{min}, y_{min}, x_{max},y_{max})$\n",
    "\n",
    "**YOLO** : $(x_{center-norm},y_{center-norm}, w_{norm}, h_{norm})$\n",
    "\n",
    "$x_{norm}$ = $\\frac{x}{widthofWholeImage}$\n",
    "\n",
    "$y_{norm}$ = $\\frac{y}{heightofWholeImage}$\n",
    "\n",
    "$w_{norm}$ = $\\frac{w}{widthofWholeImage}$\n",
    "\n",
    "$h_{norm}$ = $\\frac{h}{heightofWholeImage}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "380e9c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bbox_to_yolo(\n",
    "    size: tuple[int, int], box: tuple[int, int, int, int]\n",
    ") -> tuple[int, int, int, int]:\n",
    "    \"\"\"Convert bounding box coordinates from PASCAL VOC format to YOLO format.\n",
    "\n",
    "    :param size: A tuple of the image size: (width, height)\n",
    "    :param box: A tuple of the PASCAL VOC bbox: (xmin, ymin, xmax, ymax)\n",
    "    :return: A tuple of the YOLO bbox: (x_center, y_center, width, height)\n",
    "    \"\"\"\n",
    "    # Calculate relative dimensions\n",
    "    dw = 1.0 / size[0]\n",
    "    dh = 1.0 / size[1]\n",
    "\n",
    "    # Calculate center, width, and height of the bbox in relative dimension\n",
    "    rel_x_center = (box[0] + box[2]) / 2.0 * dw\n",
    "    rel_y_center = (box[1] + box[3]) / 2.0 * dh\n",
    "    rel_width = (box[2] - box[0]) * dw\n",
    "    rel_height = (box[3] - box[1]) * dh\n",
    "\n",
    "    return (rel_x_center, rel_y_center, rel_width, rel_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b72dff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_txt(input_file: Path, output_txt: Path, classes: dict[str, int]):\n",
    "    \"\"\"Parse an XML file in PASCAL VOC format and convert it to YOLO format.\n",
    "\n",
    "    :param input_xml: Path to the input XML file.\n",
    "    :param output_txt: Path to the output .txt file in YOLO format.\n",
    "    :param classes: A list of class names as strings.\n",
    "    \"\"\"\n",
    "    # Load and parse the XML file\n",
    "    if input_file.suffix == \".txt\":\n",
    "        # Try to parse .txt as XML\n",
    "        try:\n",
    "            # Attempt to parse the file content as XML\n",
    "            with input_file.open(\"r\", encoding=\"utf-8\") as file:\n",
    "                file_content = file.read()\n",
    "            root = ET.fromstring(file_content)\n",
    "        except ET.ParseError as e:\n",
    "            print(f\"Error parsing {input_file}: {e}\")\n",
    "            return  # Skip this file and continue with the next\n",
    "    else:\n",
    "        # Try parsing the XML file (expects XML format)\n",
    "        try:\n",
    "            tree = ET.parse(input_file)\n",
    "            root = tree.getroot()\n",
    "        except ET.ParseError as e:\n",
    "            print(f\"Error parsing {input_file}: {e}\")\n",
    "            return  # Skip this file and continue with the next\n",
    "\n",
    "    # Extract image dimensions\n",
    "    size_element = root.find(\"size\")\n",
    "    image_width = int(size_element.find(\"width\").text)\n",
    "    image_height = int(size_element.find(\"height\").text)\n",
    "\n",
    "    with output_txt.open(\"w\") as file:\n",
    "        # Process each object in the XML\n",
    "        for obj in root.iter(\"object\"):\n",
    "            is_difficult = obj.find(\"difficult\").text\n",
    "            class_name = obj.find(\"name\").text\n",
    "\n",
    "            # Skip \"difficult\" objects or if the name is not in classes\n",
    "            if class_name not in classes or int(is_difficult) == 1:\n",
    "                continue\n",
    "\n",
    "            class_id = classes[class_name]\n",
    "\n",
    "            # Extract and convert bbox\n",
    "            xml_box = obj.find(\"bndbox\")\n",
    "            bbox = (\n",
    "                float(xml_box.find(\"xmin\").text),\n",
    "                float(xml_box.find(\"ymin\").text),\n",
    "                float(xml_box.find(\"xmax\").text),\n",
    "                float(xml_box.find(\"ymax\").text),\n",
    "            )\n",
    "            yolo_bbox = convert_bbox_to_yolo((image_width, image_height), bbox)\n",
    "\n",
    "            # Write to the output file in YOLO format\n",
    "            file.write(f\"{class_id} {' '.join(map(str, yolo_bbox))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64426385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_pascal_to_yolo_one_dataset_group(\n",
    "    files_list: list[tuple[Path, Path]],\n",
    "    to_path_with_group: Path,\n",
    "    mapping: dict[str, int],\n",
    "):\n",
    "    to_images_path = to_path_with_group / \"images\"\n",
    "    to_labels_path = to_path_with_group / \"labels\"\n",
    "    to_images_path.mkdir(parents=True, exist_ok=True)\n",
    "    to_labels_path.mkdir(parents=True, exist_ok=True)\n",
    "    for image, xml in tqdm(files_list):\n",
    "        shutil.copy(image, to_images_path / image.name)\n",
    "        to_child_path = to_labels_path / xml.with_suffix(\".txt\").name\n",
    "        xml_to_txt(xml, to_child_path, mapping)\n",
    "\n",
    "\n",
    "def map_pascal_to_yolo_dataset(\n",
    "    files_list: list[tuple[Path, Path]], to_path_top: Path, mapping: dict[int, int]\n",
    "):\n",
    "    rng = random.Random(x=42)\n",
    "    rng.shuffle(files_list)\n",
    "    train_end_idx = int(len(files_list) * 0.7)\n",
    "    test_end_idx = int(len(files_list) * (0.7 + 0.15))\n",
    "    train_files = files_list[0:train_end_idx]\n",
    "    test_files = files_list[train_end_idx:test_end_idx]\n",
    "    val_files = files_list[test_end_idx:]\n",
    "    vs = [train_files, test_files, val_files]\n",
    "    for i, g in tqdm(enumerate(DATASET_GROUPS)):\n",
    "        map_pascal_to_yolo_one_dataset_group(vs[i], to_path_top / g, mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3de6f02",
   "metadata": {},
   "source": [
    "### DSPCBSD-.v1i.yolov11: DsPCBSD+ Dataset\n",
    "\n",
    "From https://www.nature.com/articles/s41597-024-03656-8\n",
    "\n",
    "Most comprehensive of all datasets, i.e. has most classes. So we have used its class names for the entire aggregated dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7115e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "DSCPBSD_MAP = {\n",
    "    0: SHORT,\n",
    "    1: SPUR,\n",
    "    2: SPURIOUS_COPPER,\n",
    "    3: OPEN,\n",
    "    4: MOUSE_BITE,\n",
    "    5: HOLE_BREAKOUT,\n",
    "    6: SCRATCH,\n",
    "    7: CONDUCTOR_FOREIGN_OBJECT,\n",
    "    8: BASE_MATERIAL_FOREIGN_OBJECT,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "612bd64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5124it [00:54, 93.86it/s] 0<?, ?it/s]\n",
      "759it [00:07, 97.47it/s] 00<02:00, 60.37s/it]\n",
      "1484it [00:15, 94.33it/s] 4<00:33, 33.17s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:34<00:00, 31.48s/it]\n"
     ]
    }
   ],
   "source": [
    "map_dataset(Path(\"./DSPCBSD-.v1i.yolov11/\"), FINAL_DATA_DIR, DSCPBSD_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f6b45e",
   "metadata": {},
   "source": [
    "### MIXED PCB DEFECT DATASET\n",
    "\n",
    "From: https://data.mendeley.com/datasets/fj4krvmrr5/2\n",
    "\n",
    "Has similar data, but is labelled differently, so we need to map the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1c0bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIXED_PCB_DEFECT_DATASET_MAPPING = {\n",
    "    0: MISSING_HOLE,\n",
    "    1: MOUSE_BITE,\n",
    "    2: OPEN,\n",
    "    3: SHORT,\n",
    "    4: SPUR,\n",
    "    5: SPURIOUS_COPPER,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d71cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1720it [00:18, 92.26it/s] 0<?, ?it/s]\n",
      "11it [00:00, 94.25it/s]0:21<00:43, 21.91s/it]\n",
      "10it [00:00, 107.50it/s]:22<00:09,  9.19s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.45s/it]\n"
     ]
    }
   ],
   "source": [
    "map_dataset(\n",
    "    Path(\"./MIXED PCB DEFECT DETECTION/\"),\n",
    "    FINAL_DATA_DIR,\n",
    "    MIXED_PCB_DEFECT_DATASET_MAPPING,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769c8ab",
   "metadata": {},
   "source": [
    "### PCB_DATASET\n",
    "\n",
    "From https://www.kaggle.com/datasets/akhatova/pcb-defects by The Open Lab on Human Robot Interaction of Peking University\n",
    "\n",
    "It is in Pascal VOC format, so we must first convert it to YOLO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4140d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCB_DATASET_MAPPING = {\n",
    "    \"missing_hole\": MISSING_HOLE,\n",
    "    \"mouse_bite\": MOUSE_BITE,\n",
    "    \"spurious_copper\": SPURIOUS_COPPER,\n",
    "    \"short\": SHORT,\n",
    "    \"spur\": SPUR,\n",
    "    \"open_circuit\": OPEN,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd2a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCB_DATASET_PATH = Path(\"./PCB_DATASET/\")\n",
    "files_list = []\n",
    "for category in (PCB_DATASET_PATH / \"images\").iterdir():\n",
    "    for image_file in category.iterdir():\n",
    "        data_file = (\n",
    "            PCB_DATASET_PATH\n",
    "            / \"Annotations\"\n",
    "            / category.name\n",
    "            / (image_file.with_suffix(\".xml\").name)\n",
    "        )\n",
    "        files_list.append((image_file, data_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dceebf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 485/485 [00:35<00:00, 13.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [00:09<00:00, 11.49it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [00:09<00:00, 11.06it/s]\n",
      "3it [00:54, 18.03s/it]\n"
     ]
    }
   ],
   "source": [
    "map_pascal_to_yolo_dataset(files_list, FINAL_DATA_DIR, PCB_DATASET_MAPPING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0572e5a7",
   "metadata": {},
   "source": [
    "### DeepPCB-master\n",
    "\n",
    "From https://github.com/tangsanli5201/DeepPCB\n",
    "\n",
    "It's images are black & white, so we are ignoring it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f130b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
